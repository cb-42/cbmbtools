---
title: "Untitled 16S Analysis"
author: "Christopher A. Brown"
date: "July 25, 2019"
output: pdf_document
---
---
geometry: margin = 1.25cm
---
This report was built with R version `r getRversion()`. 

```{r rmd_setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, # whether code should be displayed in document
                      cache = TRUE, # whether to cache results of code chunks for future knits
                      fig.align = 'center', # alignment options: 'left', 'right', 'center', 'default'
                      error = TRUE # display error messages in document (TRUE) or stop render on error (FALSE)
                      )
```

```{r notes, include = FALSE}
# space for notes/to do list/goals that shouldn't be included in resulting report
```

```{r libraries, message = FALSE}
# This section contains a list of typical libraries used and others (commented out) that could be useful in other situations

# I. universal data wrangling and visualization
library(tidyverse)      # ggplot, dplyr, purrr, forcats, stringr... and other packages. See https://tidyverse.tidyverse.org/

# II. formatting, plotting
library(scales)         # used in formatting relative abundance % labels; dollar_format()
library(knitr)          # necessary for kable, for displaying nicer tables in html/pdf output
library(RColorBrewer)   # for generating custom palettes
# library(grid)         
# library(gridExtra)      # grid.arrange(); plot & table arranging
# library(gganimate)      # useful for comparing data across time points or changes in a single categorical variable

# III. machine learning & analysis packages
library(vegan)          # decostand(), metaMDS(), scores(), rda(), ordispider(), adonis()
library(MASS)           # isoMDS(); masks dplyr::select()
library(mvabund)
# library(randomForest)   # randomForest()
# library(caret)          # vast support for all flavors of predictive models

# IV. functions for automating and streamlining workflow
# if (!require(devtools)) install.packages("devtools")
# devtools::install_github("https://github.com/cb-42/cbmbtools")
# devtools::update_packages("cbmbtools")
library(cbmbtools)
```

# I. Data Preparation

```{r load_16s, message = FALSE, include = FALSE}
# For ease of use, place the processed 16S data files of interest into the same directory as your current RStudio project

# Basic processing with selection of OTUs > 0.1 % of the population
# I. Read in opti_mcc.shared
otu_good <- load_shared(shared = "miseq.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.opti_mcc.shared")

# Trim _S from end of rownames(otu_good); note that it may be useful to keep these well identifiers in some analyses
rownames(otu_good) <- str_remove(rownames(otu_good), "_S\\d+")

# It's a good idea to inspect the data regularly with tools such as dim(), str(), head(), tail(), summary()... This will help in catching errors earlier
dim(otu_good) # dim(otu_good)[1] observations (samples) x dim(otu_good)[2] features (OTUs above .1% population threshold)

# II. Read in cons.taxonomy
otu.good.taxonomy <- load_tax("miseq.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.opti_mcc.0.03.cons.taxonomy", otu_good = otu_good)
dim(otu.good.taxonomy)
```

```{r metadata_wrangling, include = FALSE}
# Load in metadata/environmental data, or create it

# Examples of metadata creation
otu_df <- data.frame(decostand(otu_good, "total") * 100, Sample_name = row.names(otu_good), stringsAsFactors = FALSE) %>%
  # Create Experiment from first string of characters prior to first "_"
  mutate(Experiment = factor(case_when(str_detect(Sample_name, "Exp\\d") ~ str_extract(Sample_name, "Exp\\d"),
                                       str_detect(Sample_name, "^AE_") ~ "AE",
                                       str_detect(Sample_name, "^empty_") ~ "Empty",
                                       str_detect(Sample_name, "^IsoCtrl_") ~ "IsoCtrl",
                                       str_detect(Sample_name, "^Water|^WATER") ~ "WaterNeg",
                                       str_detect(Sample_name, "^Mock") ~ "Mock"),
                             levels = c("Exp1", "Exp2", "AE", "Empty", "IsoCtrl", "WaterNeg", "Mock"))
         ) %>%
  # Create Day; account for empty_D1 and empty_D2 which refer to wells and not days
  mutate(Day = factor(case_when(str_detect(Sample_name, "_D\\d+_") & Experiment != "Empty" ~ str_extract(Sample_name, "D\\d+"))
                      ) # sum(is.na(otu_df$Day)) returns __ (as expected, controls have NA in this column)
         ) %>%
  # Create Organ
  mutate(Organ = factor(case_when(str_detect(Sample_name, "_Cecum_") ~ "Cecum",
                                  str_detect(Sample_name, "_Colon_") ~ "Colon",
                                  str_detect(Sample_name, "_Feces_") ~ "Feces"),
                        levels = c("Feces", "Colon", "Cecum")
                ) # sum(is.na(otu_df$Organ)) returns __ (as expected, controls have NA in this column)
         ) %>%
  # Create Mouse
  mutate(Mouse = as.numeric(str_extract(Sample_name, "(?<=M)\\d+")
              ) # sum(is.na(otu_df$Mouse)) returns __ (as expected, the controls have NA in this column)
         ) %>%
  # Create Run
  mutate(Run = str_extract(Sample_name, "(?<=N)\\d$")
         ) %>%
  # metadata columns at front, followed by all of the count data
  dplyr::select(Sample_name:Run, everything())
  # note that the data is in wide format
```

After the data was processed using mothur(v.1.39.4), it was put through standardization methods for community ecology using the vegan package (version `r packageVersion("vegan")`) in R. Next, any OTU count that made up less than .1% of the total OTU count for any given sample was set to 0. Subsequently, any OTUs which had a value of 0 for sum of counts across all samples were removed from the data, leaving `r dim(otu_good)[2]` OTUs for further analysis. There are `r dim(otu_good)[1]` samples when including all controls and experiments.

```{r summary_table}
# Use knitr::kable to generate a table summarizing key information about the experiment, e.g. number of samples by treatments
```

\newpage
# II. Analysis of controls
## 2.1 Mock
[Descriptive text here]

```{r analyze_mock}
# example code
mock_gg <- dplyr::filter(otu_df, Experiment == "Zymo_Mock") %>%
  tsg_ind(geo_mean = TRUE, ar_mean = TRUE)
```

```{r plot_mock, fig.width = 12, fig.height = 12}
plot_ra(df = mock_gg, title = "Cross-Comparison of Mock Control Replicates", facet_var = "Sample_name", fill = "Sample_name", yvar = "Percentage")
```

\newpage
## 2.2 Water
[Descriptive text here] 

```{r analyze_water}
# example code
water_gg <- dplyr::filter(otu_df, Experiment == "Water_Neg") %>%
  tsg_ind(geo_mean = TRUE, ar_mean = TRUE)
```

```{r plot_water, fig.width = 12, fig.height = 12}
plot_ra(df = water_gg, title = "Cross-Comparison of Negative Water Control Replicates", facet_var = "Sample_name", fill = "Sample_name", yvar = "Percentage")
```

\newpage
## 2.3 AE
[Descriptive text here] 

```{r analyze_ae}
ae_gg <- filter(otu_df, Experiment == "AE") %>%
  tsg_ind(geo_mean = TRUE, ar_mean = TRUE)
```

```{r plot_ae, fig.width = 12, fig.height = 12}
plot_ra(df = ae_gg, title = "Cross-Comparison of AE Control Replicates", facet_var = "Sample_name", fill = "Sample_name", yvar = "Percentage")
```

\newpage
## 2.4 Empty wells
[Descriptive text here]

```{r analyze_empty}
empty_gg <- filter(otu_df, Experiment == "Empty") %>%
  tsg_ind(geo_mean = TRUE, ar_mean = TRUE)
```

```{r plot_empty, fig.width = 12, fig.height = 12}
plot_ra(df = empty_gg, title = "Cross-Comparison of Empty Wells", facet_var = "Sample_name", fill = "Sample_name", yvar = "Percentage")
```

\newpage
# III. PCA  
[Descriptive text here]

```{r pca_prep}
# example: filter out controls
otu_good2 <- dplyr::filter(otu_df, !(Experiment %in% c("AE", "Empty", "IsoCtrl", "Water_Neg", "Zymo_Mock"))) %>%
  droplevels() # remove levels that are no longer present due to filtering

# PCA of all data (non-control)
otu_good2_hel <- decostand(dplyr::select(otu_good2, contains("Otu")), "hellinger")
otu_good2_pca <- rda(otu_good2_hel)

# (summary(otu_good2_pca)) # 0.3006 0.10995 0.06362 proportion explained by first 3 axes
```
